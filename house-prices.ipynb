{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis\n\nImporting modules and getting the data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Core Modules\nimport pandas as pd\nimport numpy as np\n\n# Basic modules for data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load data into a pandas DataFrame from given filepath\ntrain_path=\"../input/house-prices-advanced-regression-techniques/train.csv\"\ntest_path=\"../input/house-prices-advanced-regression-techniques/test.csv\"\n\ntrain=pd.read_csv(train_path)\ntest=pd.read_csv(test_path)\n\nhousing = train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting column names of the dataframe\nhousing.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting number of features and observations\nhousing.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 1460 training examples in the dataset and 81 attributes.\nOne attribute is SalePrice which is the target variable and another the house Id, we can then say that we have 79 attributes that we can use for the analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exploring the top of the dataframe\nhousing.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I drop the column Id because it is not a useful attribute, and I check the description of the data\nhousing = housing.drop(\"Id\", axis=1)\nhousing.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have a mix of numerical and categorical variables. Several variebles have null values."},{"metadata":{"trusted":true},"cell_type":"code","source":"# List of numerical attributes\nnum = housing.select_dtypes(exclude=['object']).columns\nprint(num)\nprint(len(num))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# List of categorical attributes\ncat = housing.select_dtypes(exclude=['number']).columns\nprint(cat)\nprint(len(cat))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"There are 37 numerical and 43 categorical attributes in the dataset.\nWe get statistical summary for each of the two."},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Descriptive statistics with up to 2 decimals\n# call transpose() for a better view of the results\nhousing.select_dtypes(exclude=['object']).describe().round(decimals=2).transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Descriptive statistics of the categorical value\nhousing.select_dtypes(exclude=['number']).describe().round(decimals=2).transpose()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For the categorical attributes we get the number of unique values and the top value for each attribute.\nFor example 'HouseStyle' has 8 unique values, of which '1Story' is the most common with 726 occurrances."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Descriptive statistics summary of the target variable\nhousing['SalePrice'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution plot of the target variable\nsns.distplot(housing['SalePrice']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the plot we see that the variable is skewed, in fact the summary statistics indicate that 50% of the prices are below 163k (median) while the average price is 180k.\n\nI apply a log transformation, by taking the log of the variable, in order to reduce the skew. This is important because I am going to apply linear regression which does not handle very good skewed data."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Log transformation to make the distribution more normal\nsns.distplot(np.log(housing['SalePrice']))\nplt.title('Distribuition of log-transformed SalesPrice')\nplt.xlabel('log(SalesPrice)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The plot looks now more normally distributed.\n\nWe can plot the distribution of the other 36 numerical attributes as well.\n "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filtering and create a copy of the numerical variables and excluding SalePrice\nnum_var = housing.select_dtypes(exclude = ['object']).drop(['SalePrice'], axis=1).copy()\n\n# Plotting the variables\nfig  = plt.figure(figsize=(14,20))\nfor i in range (len(num_var.columns)):\n    fig.add_subplot(9, 4, i+1) # (nrows, ncols, index)\n    #narrowing the bandwidth with kde_kws https://stackoverflow.com/a/61924418\n    #hist= plot a (normed) histogram.\n    #rug = draw a rugplot on the support axis.\n    sns.distplot(num_var.iloc[:,i].dropna(), kde_kws={'bw': 0.1}, hist = False, rug = True)\n    plt.xlabel(num_var.columns[i])\n    \nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The plot show that the variables have different distributions and scales. \nSome Variables are very skewed such as 'LotArea'."},{"metadata":{},"cell_type":"markdown","source":"### Dealing with outliers"},{"metadata":{},"cell_type":"markdown","source":"We can use box plots to spot outliers."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the variables on box plots\nfig  = plt.figure(figsize=(10,15))\nfor i in range (len(num_var.columns)):\n    fig.add_subplot(9, 4, i+1) # (nrows, ncols, index)\n    sns.boxplot(y=num_var.iloc[:,i].dropna())\n    \nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From a visual exploartion of the variables throught the box plots above, we can see that some variables have outliers, such as 'LotFrontage' (values above 200) and 'LotArea' (values above 150000)."},{"metadata":{},"cell_type":"markdown","source":"### Correlations among numerical variables"},{"metadata":{},"cell_type":"markdown","source":"We check whether some pairs of variables are highly correlated and remove them. Ideally we would like independent features.\n\nWe use the corr() method which returns the correlation for all pairs of variables in a range between -1 and 1, which 0 meaning no correlation. \n\nWe visualize the correlation with a heatmap."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation of numerical variables\ncorr = housing.corr()\n\n# Using mask to get triangular correlation matrix\n# https://www.kdnuggets.com/2019/07/annotated-heatmaps-correlation-matrix.html\nf, ax = plt.subplots(figsize = (15,15))\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)]=True\n\nsns.heatmap(corr, \n            mask=mask, \n#             cmap=sns.diverging_palette(220,10, as_cmap=True), \n            cmap = 'coolwarm',\n            square = True, \n            ax=ax, \n            vmin = -1.0, \n            vmax =1.0, \n            linewidths = .5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The heatmap shows some high correlations with the SalePrice (dark orange/red). We check the actual values of the correlations to confirm this."},{"metadata":{"trusted":true},"cell_type":"code","source":"corr['SalePrice'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'OverallQual' and 'GrLivArea' seem highly correlated with 'SalePrice' because their values are close to 1. This means that when one of the two variables increase, SalePrice increase as well. 'PoolArea' and 'MoSold' have values close to 0 so they are not correlated to 'SalePrice'."},{"metadata":{},"cell_type":"markdown","source":"We create a scatterplot of these two highest correlated variables with 'SalePrice' to have a better visualisation of the relationship."},{"metadata":{"trusted":true},"cell_type":"code","source":"var = ['SalePrice', 'OverallQual', 'GrLivArea']\nsns.pairplot(housing[var])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Again we see that as the 'OverallQual' and 'GrLivArea' are highly correlated with 'SalePrice' : as one of the variables increase, SalePrice increases.\n\nWe can show this relationship with different plots as well."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Barplot\nsns.barplot(housing.OverallQual, housing.SalePrice)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Boxplot\nsns.boxplot(x=housing.OverallQual, y=housing.SalePrice)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These plots show again that as the overall quality of the house the price increase, but they also show that houses with higher quality have more variety in prices. "},{"metadata":{},"cell_type":"markdown","source":"We explore the relationship between SalePrice and YearBuilt, to check whether the age of the house influeces its price."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a dataframe with only the variables of interest\nage_price = pd.concat([housing['SalePrice'], housing['YearBuilt']], axis=1)\nf, ax = plt.subplots(figsize=(32, 16))\nfig = sns.boxplot(x='YearBuilt', y='SalePrice', data=age_price)\nfig.axis(ymin=0, ymax=housing['SalePrice'].max());\nplt.xticks(rotation=90);\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Newer houses tend to cost more, but there are also some old houses with higher prices. This correlation is not as strong as the one between 'OverallQual' and 'SalePrice'."},{"metadata":{},"cell_type":"markdown","source":"We get the correlation for all the other variables as well. If two variables are hightly correlated we can consider removing one of them."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Only correlations above 0.5 and not auto-correlations, remove NaN and build a dictionary\n# unstack to output a series\nhigh_corrs = (corr[abs(corr) > 0.5][corr != 1.0]).unstack().dropna().to_dict()\nunique_high_corrs = pd.DataFrame(list(set([(tuple(sorted(key)), \n                                            high_corrs[key])for key in high_corrs])), \n                                 columns=['attribute pair', 'correlation'])\n\n# Sorted by absolute value\nunique_high_corrs = unique_high_corrs.iloc[abs(unique_high_corrs['correlation']).argsort()[::-1]]\n\nunique_high_corrs    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"GarageCars and GarageArea are highly correlated. Because they also intuitively express similar features, we can drop one of them. Specifically it is better to drop GarageArea, since GarageCars is also highly correlated with SalePrice. \nWe can also drop varibles that have very small correlation with SalePrice, such as MoSold, 3SsnPorch and BsmtFinSF2."},{"metadata":{},"cell_type":"markdown","source":"### Explore categorical attributes"},{"metadata":{},"cell_type":"markdown","source":"We now do some exploratory data analysis on the categorical attributes"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We check the relationship between KitchenQual and prices."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Boxplot\nf, ax = plt.subplots(figsize = (10,6))\nsns.boxplot(x=housing.KitchenQual, y=housing.SalePrice)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Houses with KitchenQual value Ex are more expensive (and also have slightly more variety in prices), while the Fa ones are the cheapest options.\n\nWe check now the style of the house and its relation with the price. We look at a box plot and the frequecy distribution of the values."},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(12,8))\nsns.boxplot(y=housing.SalePrice, x=housing.HouseStyle)\nplt.show()\n\n# Count of categories within HouseStyle attribute\nfig = plt.figure(figsize=(12, 4))\nsns.countplot(x='HouseStyle', data=housing)\nplt.ylabel('Frequency')\nplt.show()\n\n\nhousing.HouseStyle.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The most expensive option is the 2story and this option has also the largest variety in prices. \n\nMost of the houses are 1story.\n\nWe can plot the style of the house agaisnt the years to check whether the style has changed over the years."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(housing.YearBuilt,housing.HouseStyle)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the plot above we see that 1Story and 2Story are consistent over the years (a little more frequent in recent years) while 2.5Fin, 2.5Unf and 1.5Unf are all older houses and SFoyer and SLvl are all newer houses."},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"## Dealing With Missing Values"},{"metadata":{},"cell_type":"markdown","source":"We get a sorted count of the missing values for all the attributes."},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.isnull().sum().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of the categorical atttributes have missing values where the feature is not prensent, for example 'PoolQC' is NaN if the house does not have a pool.\n\nSo for the categorical values I will replace the missing values with None, except 'Electrical' (Electrical system), which will be filled with the mode.\n\nThen for 'LotFrontage', which is the linear feet of street connected to property, I will fill the missing value with the median of the value for that attribute in the same neighborhood.\n\nThe numerical attributes will be filled with the zero.\n\nThe attribute 'Utilities' (Type of utilities available) will be dropped because not interesting for this model.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Imputing Missing Values\n\nhousing_fillNa = housing\n\n# Categorical columns:\ncat_cols_fill_none = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu',\n                     'GarageCond', 'GarageQual', 'GarageFinish', 'GarageType',\n                     'BsmtFinType2', 'BsmtExposure', 'BsmtFinType1', 'BsmtQual', 'BsmtCond',\n                     'MasVnrType']\n\n# Replace missing values for categorical columns with None\nfor cat in cat_cols_fill_none:\n    housing_fillNa[cat] = housing_fillNa[cat].fillna(\"None\")\n    \n# Use the mode value for Electrical\nhousing_fillNa['Electrical'] = housing_fillNa['Electrical'].fillna(housing_fillNa['Electrical']).mode()[0]\n    \n# Group by neighborhood and fill in missing value by the median LotFrontage of all the neighborhood\nhousing_fillNa['LotFrontage'] = housing_fillNa.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median()))    \n\n# Garage: GarageYrBlt, GarageArea, GarageCars and MasVnrArea these are numerical columns, replace with zero\nfor col in ['GarageYrBlt', 'GarageArea', 'GarageCars', 'MasVnrArea']:\n    housing_fillNa[col] = housing_fillNa[col].fillna(int(0))\n\n# There is no need of Utilities so let's just drop this column\nhousing_fillNa = housing_fillNa.drop(['Utilities'], axis=1)\n\n# Get the count again to verify that we do not have any more missing values\nhousing_fillNa.isnull().apply(sum).max()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dealing with Outliers "},{"metadata":{},"cell_type":"markdown","source":"In order to remove the outliers, we remove the datapoints that are above the 99.9% quantile."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Numerocal attributes without NaN\nnum_attr = housing_fillNa.select_dtypes(exclude='object')\n\nquantile = housing_fillNa.quantile(.999)\n\nfor col in num_attr.columns:\n    housing_fillNa = housing_fillNa.drop(housing_fillNa[col][housing_fillNa[col]>quantile[col]].index)\n\nhousing_fillNa.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After removing the outliers, we are now left with 1422 rows."},{"metadata":{},"cell_type":"markdown","source":"## Dealing with Correlated Attributes"},{"metadata":{},"cell_type":"markdown","source":"We remove the highly-correlated features, which we have identified previously. As for GarageArea and GarageCars, they are highly-correlated, however we will drop GarageArea because GarageCars is more correlated with price than area."},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Remove highly correlated features as identified for excluding in prev scatter plots & corr values\nattributes_drop = ['MiscVal', 'MoSold', 'YrSold', 'BsmtFinSF2','BsmtHalfBath','MSSubClass',\n                   'GarageArea', 'GarageYrBlt', '3SsnPorch']\n\nhousing_fillNa = housing_fillNa.drop(attributes_drop, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Handle Text And Categorical Attributes"},{"metadata":{},"cell_type":"markdown","source":"We convert categorical number from text to number with one-hot encoding, where the value of the attribute will be 1 if it is present, and 0 if not."},{"metadata":{"trusted":true},"cell_type":"code","source":"# One-hot encoding of categorical attributes\nfrom sklearn.preprocessing import OneHotEncoder\ncat_encoder = OneHotEncoder()\nhousing_fillNa_1hot = cat_encoder.fit_transform(housing_fillNa)\nhousing_fillNa_1hot","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After this process, we have 7333 attributes, while before we had only 70."}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}